{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SaturaÃ§Ã£o do **GRADIENTE**\n",
    "\n",
    "Geralmente ocorre em funÃ§Ãµes de ativaÃ§Ã£o nÃ£o lineares como Sigmoid e Tangente HiperbÃ³lica (tanh), acontece quando os gradientes se tornam muito pequenos, dificultando o aprendizado da rede\n",
    "\n",
    "âœ… Para evitar saturaÃ§Ã£o:\n",
    "\n",
    "- Prefira ReLU, Leaky ReLU ou ELU em vez de sigmoide/tanh.\n",
    "\n",
    "- Use Batch Normalization, que mantÃ©m os valores das ativaÃ§Ãµes dentro de uma faixa saudÃ¡vel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuga do **GRADIENTE**\n",
    "\n",
    "Ocorre quando os gradientes se tornam muito grandes, fazendo com que os pesos explodam e a rede fique instÃ¡vel. Esse problema Ã© comum em redes muito profundas, principalmente com funÃ§Ãµes de ativaÃ§Ã£o que nÃ£o possuem limite superior. pode acontecer em **Redes Recorrentes**, **Variantes da ReLU (Leaky ReLU, PReLU, ELU)**, funÃ§Ãµes que nÃ£o possuem **limite superior para os valores da ativaÃ§Ã£o**.\n",
    "\n",
    "âœ… Para evitar fuga do gradiente:\n",
    "\n",
    "- Use InicializaÃ§Ã£o de Pesos adequada (ex: He Initialization para ReLU).\n",
    "\n",
    "- Utilize Batch Normalization para manter os gradientes sob controle.\n",
    "\n",
    "- Gradiente Clipping: Limita o tamanho do gradiente para evitar explosÃ£o.\n",
    "\n",
    "- RegularizaÃ§Ã£o L2 (Weight Decay): Penaliza pesos muito grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeakyRelu\n",
    "\n",
    "Utilizando a funÃ§Ã£o de ativaÃ§Ã£o *RelU* (onde o valor de entrada positivo permanece o mesmo, enquanto uma entrada negativa se torna zero), pode ser que o nosso modelo mate alguns neurÃ´nios pois se um neurÃ´nio recebe valores negativos continuamente, sempre retornarÃ¡ zero. A *LeakyRelu* visa consertar isso. Em sua funÃ§Ã£o, ao invÃ©s de zerar valores de entrada negativa, ela os transforma em um fator Î± pequeno, geralmente Î± = 0.01, fazendo assim que em algum momento aquele neurÃ´nio \"volte a vida\", aprendendo novamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Como escolher a funÃ§Ã£o de ativaÃ§Ã£o da Ãºltima camada?\n",
    "\n",
    "| **Tipo de Problema**                                          | **FunÃ§Ã£o de AtivaÃ§Ã£o na SaÃ­da**         | **ExplicaÃ§Ã£o** |\n",
    "|--------------------------------------------------------------|---------------------------------|--------------|\n",
    "| **ClassificaÃ§Ã£o binÃ¡ria** (2 classes: \"sim/nÃ£o\", \"gato/cachorro\") | `sigmoid`                     | Retorna um valor entre **0 e 1**, interpretado como **probabilidade**. |\n",
    "| **ClassificaÃ§Ã£o multiclasse** (3 ou mais classes, previsÃ£o de uma Ãºnica classe) | `softmax`                     | Converte os logits em **probabilidades normalizadas** (somam 1), Ãºtil para **1 classe por amostra**. |\n",
    "| **ClassificaÃ§Ã£o multirrÃ³tulo** (cada amostra pode ter vÃ¡rias classes) | `sigmoid`                      | Cada saÃ­da pode ser ativada independentemente, pois cada rÃ³tulo Ã© tratado separadamente. |\n",
    "| **RegressÃ£o** (previsÃ£o de valores contÃ­nuos, como temperatura, preÃ§o de casa) | `linear` (ou nenhuma ativaÃ§Ã£o) | Permite qualquer valor real como saÃ­da, sem restriÃ§Ãµes. |\n",
    "| **RegressÃ£o para valores positivos** (exemplo: previsÃ£o de contagem) | `relu` ou `softplus`          | Garante que a saÃ­da seja **sempre positiva**. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\OneDrive\\Desktop\\RedesNeurais-Basico\\environment\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\anton\\OneDrive\\Desktop\\RedesNeurais-Basico\\environment\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), # Tamanho das imagens\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2), # pode ser \"PReLU()\" no lugar da LeakyReLU, mas se quiser usar SELU precisa definir \"activation='selu'\" e \"kernel_initializer='cun_normal'\"\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Dense(10, activation='softmax') # 10 pois sÃ£o 10 classes possÃ­veis de saÃ­da. (classes das fotos do MNIST)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4755 - loss: 1.6578 - val_accuracy: 0.7168 - val_loss: 0.8749\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7209 - loss: 0.8360 - val_accuracy: 0.7734 - val_loss: 0.7050\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.6927 - val_accuracy: 0.8020 - val_loss: 0.6257\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.6230 - val_accuracy: 0.8136 - val_loss: 0.5801\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.5804 - val_accuracy: 0.8222 - val_loss: 0.5515\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.5552 - val_accuracy: 0.8302 - val_loss: 0.5246\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.5360 - val_accuracy: 0.8314 - val_loss: 0.5095\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8280 - loss: 0.5122 - val_accuracy: 0.8360 - val_loss: 0.4960\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.5060 - val_accuracy: 0.8394 - val_loss: 0.4821\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.4938 - val_accuracy: 0.8420 - val_loss: 0.4740\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.4818 - val_accuracy: 0.8446 - val_loss: 0.4662\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.4736 - val_accuracy: 0.8452 - val_loss: 0.4592\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.4657 - val_accuracy: 0.8478 - val_loss: 0.4525\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.4584 - val_accuracy: 0.8476 - val_loss: 0.4488\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8433 - loss: 0.4510 - val_accuracy: 0.8480 - val_loss: 0.4483\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.4438 - val_accuracy: 0.8538 - val_loss: 0.4377\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.4483 - val_accuracy: 0.8508 - val_loss: 0.4393\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.4378 - val_accuracy: 0.8518 - val_loss: 0.4326\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.4358 - val_accuracy: 0.8540 - val_loss: 0.4281\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8501 - loss: 0.4321 - val_accuracy: 0.8552 - val_loss: 0.4291\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.4329 - val_accuracy: 0.8556 - val_loss: 0.4235\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8525 - loss: 0.4257 - val_accuracy: 0.8582 - val_loss: 0.4206\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.4224 - val_accuracy: 0.8580 - val_loss: 0.4190\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.4182 - val_accuracy: 0.8576 - val_loss: 0.4183\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.4141 - val_accuracy: 0.8582 - val_loss: 0.4135\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8569 - loss: 0.4139 - val_accuracy: 0.8602 - val_loss: 0.4101\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8569 - loss: 0.4119 - val_accuracy: 0.8598 - val_loss: 0.4091\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.4036 - val_accuracy: 0.8620 - val_loss: 0.4055\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8646 - loss: 0.3963 - val_accuracy: 0.8600 - val_loss: 0.4088\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8604 - loss: 0.4017 - val_accuracy: 0.8614 - val_loss: 0.4022\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âŒ Piora no modelo\n",
    "\n",
    "Por que serÃ¡ que o modelo utilizando o leakyRelU piorou em relaÃ§Ã£o ao que fizemos no arquivo \"RedesSequenciais.ipynb\" utilizando uma rede sequencial simples?\n",
    "\n",
    "\n",
    "\n",
    "Fator |\tModelo com LeakyReLU (pior desempenho) |\tModelo com ReLU (melhor desempenho)\n",
    "|------------------------------------------------------|---------------------------------|--------------|\n",
    "FunÃ§Ã£o de ativaÃ§Ã£o |\tLeakyReLU(Î±=0.2) (mantÃ©m gradientes negativos, pode atrapalhar) |\tReLU (aprendizado mais rÃ¡pido e eficiente)\n",
    "InicializaÃ§Ã£o |\the_normal (pode gerar pesos grandes demais) |\tglorot_uniform (mais equilibrado para redes pequenas)\n",
    "Complexidade |\tMais camadas e inicializaÃ§Ãµes desnecessÃ¡rias |\tModelo mais simples e eficiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ² batch Normalization\n",
    "\n",
    "Utilizada para **normalizar** as **ativaÃ§Ãµes das camadas intermediÃ¡rias** de uma rede neural, o **BathNormalization** acelera o treinamento, melhora a performance e reduz a sensibilidade a inicializaÃ§Ã£o dos pesos.\n",
    "\n",
    "Quando treinamos uma rede neural, as ativaÃ§Ãµes das camadas podem ficar em diferentes escalas, o que pode dificultar a cnovergÃªncia durante o treinamento, jÃ¡ que o gradiente pode se tornar muito grande ou muito pequeno. Isso Ã© conhecido como **covariate shift** (MudanÃ§a na distribuiÃ§Ã£o das ativaÃ§Ãµes das camadas). O **BatchNormalization** garante que as ativaÃ§Ãµes tenham distribuiÃ§Ã£o com mÃ©dia **0** e desvio padrÃ£o **1** durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3) ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6035 - loss: 1.1884 - val_accuracy: 0.7980 - val_loss: 0.5868\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7859 - loss: 0.6183 - val_accuracy: 0.8260 - val_loss: 0.5099\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.5461 - val_accuracy: 0.8372 - val_loss: 0.4738\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.5173 - val_accuracy: 0.8464 - val_loss: 0.4516\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.4956 - val_accuracy: 0.8516 - val_loss: 0.4364\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.4687 - val_accuracy: 0.8544 - val_loss: 0.4251\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.4645 - val_accuracy: 0.8582 - val_loss: 0.4155\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.4557 - val_accuracy: 0.8600 - val_loss: 0.4089\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.4507 - val_accuracy: 0.8642 - val_loss: 0.4024\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.4291 - val_accuracy: 0.8666 - val_loss: 0.3972\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.4320 - val_accuracy: 0.8650 - val_loss: 0.3936\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.4101 - val_accuracy: 0.8666 - val_loss: 0.3881\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8562 - loss: 0.4108 - val_accuracy: 0.8686 - val_loss: 0.3854\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.3999 - val_accuracy: 0.8696 - val_loss: 0.3815\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3977 - val_accuracy: 0.8690 - val_loss: 0.3776\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8599 - loss: 0.3959 - val_accuracy: 0.8698 - val_loss: 0.3773\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8573 - loss: 0.3952 - val_accuracy: 0.8702 - val_loss: 0.3735\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3854 - val_accuracy: 0.8694 - val_loss: 0.3714\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3810 - val_accuracy: 0.8734 - val_loss: 0.3678\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3755 - val_accuracy: 0.8732 - val_loss: 0.3681\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.3782 - val_accuracy: 0.8746 - val_loss: 0.3662\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3797 - val_accuracy: 0.8734 - val_loss: 0.3620\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3656 - val_accuracy: 0.8738 - val_loss: 0.3616\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3629 - val_accuracy: 0.8730 - val_loss: 0.3594\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3650 - val_accuracy: 0.8742 - val_loss: 0.3585\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3553 - val_accuracy: 0.8760 - val_loss: 0.3575\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.3599 - val_accuracy: 0.8752 - val_loss: 0.3561\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8733 - loss: 0.3530 - val_accuracy: 0.8772 - val_loss: 0.3537\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.3511 - val_accuracy: 0.8764 - val_loss: 0.3518\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8762 - loss: 0.3464 - val_accuracy: 0.8768 - val_loss: 0.3525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27b87be3a40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez, houve uma piora pois o problema Ã© \"simples\" e nÃ£o requer um aprendizado tÃ£o profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“¥Dropout\n",
    "\n",
    "Um dos reguladores mais comuns nas redes neurais profunda sÃ£o as camadas de *Dropout*, as redes neurais mais modernas podem obter um aumento de 1 a 2% de acurÃ¡cia simplesmente por adicionar camadas de *Dropout* segundo umartigo de 2014 de **Nitish Srivastava**.\n",
    "\n",
    "Como o Dropout funciona?\n",
    "Durante o treinamento de uma rede neural, o Dropout \"desativa\" aleatoriamente um conjunto de neurÃ´nios em cada iteraÃ§Ã£o, de maneira que eles nÃ£o participam da ativaÃ§Ã£o nem do cÃ¡lculo do gradiente. Esse processo Ã© aplicado de forma estocÃ¡stica, ou seja, em cada atualizaÃ§Ã£o do modelo, diferentes neurÃ´nios sÃ£o desativados.\n",
    "\n",
    "Por exemplo, se aplicarmos um Dropout de 50%, metade dos neurÃ´nios serÃ£o desativados aleatoriamente em cada ciclo de treinamento. Isso forÃ§a a rede a aprender representaÃ§Ãµes mais robustas e a nÃ£o depender excessivamente de neurÃ´nios especÃ­ficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "logdir = os.path.join(os.curdir, \"ArquivosGeradosPelosCodigos/logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "# Criando TransBoard como callbackk\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3) ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3702 - loss: 1.8105 - val_accuracy: 0.7122 - val_loss: 0.8202\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6537 - loss: 0.9512 - val_accuracy: 0.7596 - val_loss: 0.6885\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7061 - loss: 0.8158 - val_accuracy: 0.7844 - val_loss: 0.6284\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.7476 - val_accuracy: 0.7982 - val_loss: 0.5920\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.7089 - val_accuracy: 0.8066 - val_loss: 0.5654\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7564 - loss: 0.6778 - val_accuracy: 0.8112 - val_loss: 0.5450\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.6490 - val_accuracy: 0.8192 - val_loss: 0.5305\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7720 - loss: 0.6376 - val_accuracy: 0.8240 - val_loss: 0.5167\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.6154 - val_accuracy: 0.8262 - val_loss: 0.5076\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.6037 - val_accuracy: 0.8274 - val_loss: 0.5000\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.6019 - val_accuracy: 0.8314 - val_loss: 0.4916\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.5958 - val_accuracy: 0.8324 - val_loss: 0.4871\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.5852 - val_accuracy: 0.8336 - val_loss: 0.4811\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.5732 - val_accuracy: 0.8362 - val_loss: 0.4758\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.5645 - val_accuracy: 0.8384 - val_loss: 0.4710\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: 0.5589 - val_accuracy: 0.8410 - val_loss: 0.4660\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.5592 - val_accuracy: 0.8422 - val_loss: 0.4623\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.5443 - val_accuracy: 0.8420 - val_loss: 0.4602\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8012 - loss: 0.5519 - val_accuracy: 0.8454 - val_loss: 0.4550\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.5481 - val_accuracy: 0.8462 - val_loss: 0.4512\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.5418 - val_accuracy: 0.8460 - val_loss: 0.4484\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.5380 - val_accuracy: 0.8466 - val_loss: 0.4462\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8096 - loss: 0.5315 - val_accuracy: 0.8492 - val_loss: 0.4431\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.5322 - val_accuracy: 0.8486 - val_loss: 0.4415\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.5282 - val_accuracy: 0.8490 - val_loss: 0.4421\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.5238 - val_accuracy: 0.8498 - val_loss: 0.4399\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.5270 - val_accuracy: 0.8512 - val_loss: 0.4363\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.5191 - val_accuracy: 0.8532 - val_loss: 0.4339\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.5188 - val_accuracy: 0.8528 - val_loss: 0.4328\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8156 - loss: 0.5173 - val_accuracy: 0.8536 - val_loss: 0.4290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27b87f707d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No treinamento de redes neurais, momentum e decay sÃ£o tÃ©cnicas usadas para melhorar a eficiÃªncia e estabilidade da descida do gradiente. Elas ajudam a evitar problemas como mÃ­nimos locais e oscilaÃ§Ãµes, alÃ©m de acelerar a convergÃªncia.\n",
    "\n",
    "# ğŸ¢ Momentum\n",
    "O momentum Ã© uma tÃ©cnica usada para suavizar a atualizaÃ§Ã£o dos pesos durante o treinamento. Ele funciona como uma espÃ©cie de \"memÃ³ria\" dos passos anteriores, ajudando a rede a continuar na mesma direÃ§Ã£o e reduzindo oscilaÃ§Ãµes.\n",
    "\n",
    "FÃ³rmula do Gradient Descent com Momentum:\n",
    "\n",
    "$$\n",
    "v_t = \\beta v_{t-1} + (1 - \\beta) \\nabla J(\\theta_t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_t = \\theta_{t-1} - \\alpha v_t\n",
    "$$\n",
    "\n",
    "\n",
    " BenefÃ­cios do **Momentum**:\n",
    "\n",
    "âœ… Acelera a convergÃªncia em direÃ§Ãµes consistentes.\n",
    "\n",
    "âœ… Reduz oscilaÃ§Ãµes em direÃ§Ãµes instÃ¡veis.\n",
    "\n",
    "âœ… Evita mÃ­nimos locais rasos ao manter a \"inÃ©rcia\" da atualizaÃ§Ã£o.\n",
    "\n",
    "ğŸ“Œ **Exemplo intuitivo**: Imagine uma bola rolando por um vale; o momentum faz com que ela continue se movendo mesmo se o gradiente ficar prÃ³ximo de zero por um tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Decay (Decaimento da Taxa de Aprendizado)\n",
    "O decay (ou \"learning rate decay\") controla a reduÃ§Ã£o gradual da taxa de aprendizado (ğ›¼) ao longo do treinamento. Isso ajuda a rede a fazer ajustes mais finos nos pesos Ã  medida que se aproxima da soluÃ§Ã£o Ã³tima.\n",
    "\n",
    "BenefÃ­cios do **Decay**:\n",
    "\n",
    "âœ… Permite passos grandes no inÃ­cio (exploraÃ§Ã£o) e pequenos no fim (convergÃªncia precisa).\n",
    "\n",
    "âœ… Evita que a rede fique \"presa\" em mÃ­nimos locais subÃ³timos.\n",
    "\n",
    "âœ… Aumenta a estabilidade do treinamento.\n",
    "\n",
    "ğŸ“Œ **Exemplo intuitivo**: No inÃ­cio, vocÃª dÃ¡ passos largos para encontrar uma soluÃ§Ã£o geral, mas conforme se aproxima da resposta ideal, comeÃ§a a dar passos menores para refinÃ¡-la."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ² **Resumo**\n",
    "Conceito\t| Objetivo\t| Como funciona\n",
    "-------|----------|---------\n",
    "Momentum\t| Suaviza e acelera a otimizaÃ§Ã£o\t| MantÃ©m \"memÃ³ria\" das atualizaÃ§Ãµes passadas para reduzir oscilaÃ§Ãµes e acelerar a convergÃªncia\n",
    "Decay\t| Ajusta a taxa de aprendizado ao longo do tempo\t| ComeÃ§a com um learning rate alto e o reduz gradualmente para evitar passos muito grandes no final\n",
    "\n",
    "\n",
    "Muitos  otimizadores modernos, como Adam, RMSprop e SGD com Momentum, jÃ¡ integram esses conceitos para melhorar o desempenho do treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 1.0807 - val_accuracy: 0.8242 - val_loss: 0.5056\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7884 - loss: 0.5923 - val_accuracy: 0.8402 - val_loss: 0.4622\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.5380 - val_accuracy: 0.8496 - val_loss: 0.4326\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8149 - loss: 0.5090 - val_accuracy: 0.8532 - val_loss: 0.4186\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4990 - val_accuracy: 0.8576 - val_loss: 0.4085\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.4857 - val_accuracy: 0.8518 - val_loss: 0.4139\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8280 - loss: 0.4772 - val_accuracy: 0.8594 - val_loss: 0.3957\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8282 - loss: 0.4697 - val_accuracy: 0.8638 - val_loss: 0.3908\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.4534 - val_accuracy: 0.8620 - val_loss: 0.3874\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4493 - val_accuracy: 0.8640 - val_loss: 0.3803\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.4524 - val_accuracy: 0.8676 - val_loss: 0.3737\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.4451 - val_accuracy: 0.8674 - val_loss: 0.3708\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.4418 - val_accuracy: 0.8718 - val_loss: 0.3672\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.4400 - val_accuracy: 0.8694 - val_loss: 0.3698\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.4398 - val_accuracy: 0.8642 - val_loss: 0.3769\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.4271 - val_accuracy: 0.8734 - val_loss: 0.3582\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4274 - val_accuracy: 0.8736 - val_loss: 0.3580\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8471 - loss: 0.4171 - val_accuracy: 0.8718 - val_loss: 0.3560\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.4202 - val_accuracy: 0.8714 - val_loss: 0.3536\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8478 - loss: 0.4145 - val_accuracy: 0.8768 - val_loss: 0.3507\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4162 - val_accuracy: 0.8726 - val_loss: 0.3514\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8520 - loss: 0.4077 - val_accuracy: 0.8746 - val_loss: 0.3498\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.4090 - val_accuracy: 0.8742 - val_loss: 0.3433\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.4079 - val_accuracy: 0.8746 - val_loss: 0.3478\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8511 - loss: 0.4030 - val_accuracy: 0.8782 - val_loss: 0.3415\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.4023 - val_accuracy: 0.8768 - val_loss: 0.3414\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.4015 - val_accuracy: 0.8762 - val_loss: 0.3437\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.3947 - val_accuracy: 0.8742 - val_loss: 0.3427\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8511 - loss: 0.4005 - val_accuracy: 0.8776 - val_loss: 0.3363\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8524 - loss: 0.3971 - val_accuracy: 0.8756 - val_loss: 0.3382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27b9e79db20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9, decay=0.01) ,metrics=['accuracy'])\n",
    "\n",
    "# Momentum = O valor 0.9 indica que 90% do gradiente anterior Ã© mantido para a prÃ³xima atualizaÃ§Ã£o, e apenas 10% vem do gradiente atual. Ajuda a rede a seguir na direÃ§Ã£o certa, evitando oscilaÃ§Ãµes.\n",
    "# Decay = 0.01 â†’ Reduz gradativamente a taxa de aprendizado para melhorar a precisÃ£o no final.\n",
    "\n",
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
